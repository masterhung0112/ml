{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN2LayerScratch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masterhung0112/ml/blob/master/NN2LayerScratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "KEciAOKItYD7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h8xqOdT7t9gX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " Class **dlnet** that setups and initializes our network.\n",
        "- **X**: Holds the input layer, the data given to the network. X is a matrix that has as many rows as features has our data and as many columns as samples we have available to train the network.\n",
        "- **Y**: Holds the desired output.\n",
        "- **Yh**: Holds the output that our network produces. It should have the same dimensions than Y, our desired target values. We initialize it to zero.\n",
        "- **L**: It holds the number of layers of our network, 2.\n",
        "dims: Next, we define the number of neurons or units in each of our layers. We do this with a numpy array. The first component of the array is our input (which is not counted as a layer of the network). Our input will have 9 units because, as we will see in a bit, our data-set will have 9 useful features. Next, the first layer of the neural network will have 15 neurons, and our second and final layer will have 1 (the output of the network).\n",
        "- **param**: A Python dictionary that will hold the W and b parameters of each of the layers of the network.\n",
        "- **ch**: a cache variable, a python dictionary that will hold some intermediate calculations that we will need during the backward pass of the gradient descent algorithm.\n",
        "- **lr**: Our learning rate. This sets the speed at which the network will learn.\n",
        "- **sam**: The number of training samples we have.\n",
        "- **loss**: An array where we will store the loss value of the network every x iterations. The loss value expresses the difference between the predicted output of our network and the target one."
      ]
    },
    {
      "metadata": {
        "id": "4WbimOH3tsaI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class dlnet:\n",
        "  def __init__(self, x, y):\n",
        "    self.X = x\n",
        "    self.Y = y\n",
        "    self.Yh = np.zeros((1, self.Y.shape[1]))\n",
        "    \n",
        "    self.L = 2\n",
        "    self.dims = [9, 15, 1]\n",
        "    \n",
        "    self.param = {}\n",
        "    self.ch = {}\n",
        "    self.grad = {}\n",
        "    self.loss = {}\n",
        "    self.lr = 0.003\n",
        "    self.sam = self.Y.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}